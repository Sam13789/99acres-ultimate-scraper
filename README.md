# ğŸ˜ï¸ 99acres Ultimate Property Scraper

A comprehensive, interactive property scraper for 99acres.com with granular control over cities, property types, and scraping depth.

## ğŸš€ Quick Start

1. **Launch Interactive Menu:**
   ```bash
   python run_scraper.py
   ```

2. **Process Results:**
   ```bash
   python optimized_multi_type_cleaner.py
   ```

## ğŸ¯ Features

### **Interactive Launcher (`run_scraper.py`)**
- **ğŸ§ª Quick Test:** First page, 5 cities, all types
- **ğŸ™ï¸ Medium Test:** All pages, 10 cities, all types  
- **ğŸŒŸ Full Scrape:** All cities, all pages, all types
- **ğŸ¯ Custom Scrape:** Choose everything yourself

### **Granular Control**
- **ğŸ™ï¸ City Selection:** Choose specific cities or regions (Delhi NCR, Mumbai, Bangalore, etc.)
- **ğŸ  Property Types:** Select from 5 types (Apartments, Houses, Land, Builder Floors, Farm Houses)
- **ğŸ“„ Pages Control:** First page only, specific number (1-20), or all pages

### **Organized Output Structure**
```
output/
â”œâ”€â”€ json_files/     # Raw scraped JSON data
â”œâ”€â”€ csv_files/      # Clean optimized CSV files
â””â”€â”€ excel_files/    # Excel files for analysis
```

## ğŸ› ï¸ Advanced Usage

### **Command Line Options**
```bash
# Basic usage
python comprehensive_city_scraper.py --test --max-cities 5

# Specific cities (Delhi NCR, Mumbai, Bangalore)  
python comprehensive_city_scraper.py --cities "1,12,20"

# Specific property types (Apartments and Houses only)
python comprehensive_city_scraper.py --property-types "1,2"

# Limit pages per property type
python comprehensive_city_scraper.py --max-pages 3

# Combined example
python comprehensive_city_scraper.py --cities "1,12" --property-types "1,2,4" --max-pages 5
```

### **Property Types Reference**
1. **Residential Apartments** - Flats/Apartments (excludes projects)
2. **Independent Houses/Villas** - Standalone houses
3. **Residential Land/Plots** - Land for construction
4. **Independent/Builder Floors** - Floor-wise properties
5. **Farm Houses** - Agricultural/recreational properties

## ğŸ“Š Output Files

### **CSV Files (output/csv_files/)**
- `city_name_apartments_pages.csv`
- `city_name_houses_villas_pages.csv`
- `city_name_land_plots_pages.csv`
- `city_name_builder_floors_pages.csv`
- `city_name_farm_houses_pages.csv`

### **Excel Files (output/excel_files/)**
- Individual Excel files for each property type
- `city_name_all_types_pages.xlsx` with summary sheet

## ğŸ”§ System Requirements

- **Python 3.7+**
- **Required packages:** `requests`, `pandas`, `openpyxl`
- **Input file:** `city_w_id.json` (city mapping)

## ğŸ’¡ Tips

- **Start small:** Use Quick Test to verify everything works
- **Regional focus:** Use city selection to focus on specific regions
- **Property-specific:** Select only the property types you need
- **Respectful scraping:** Built-in delays prevent overwhelming the server

## ğŸ“ Project Structure

```
ğŸ“ 99acres ultimate scraper/
â”œâ”€â”€ ğŸ“„ city_w_id.json                    # City mapping data
â”œâ”€â”€ ğŸ“„ comprehensive_city_scraper.py     # Main scraper engine
â”œâ”€â”€ ğŸ“„ optimized_multi_type_cleaner.py   # Data processor  
â”œâ”€â”€ ğŸ“„ run_scraper.py                    # Interactive launcher
â”œâ”€â”€ ğŸ“„ check_progress.py                 # Progress checker
â”œâ”€â”€ ğŸ“„ test_proxies.py                   # Proxy tester (optional)
â”œâ”€â”€ ğŸ“„ get_premium_proxies.py            # Premium proxy fetcher (optional)
â”œâ”€â”€ ğŸ“„ README.md                         # This file
â”œâ”€â”€ ğŸ“ facets/                           # Reference data mappings
â”‚   â”œâ”€â”€ ğŸ“„ AMENITIES.csv                 # Amenity ID mappings
â”‚   â”œâ”€â”€ ğŸ“„ FEATURES.csv                  # Feature ID mappings
â”‚   â””â”€â”€ ğŸ“„ *.csv                         # Other reference mappings
â””â”€â”€ ğŸ“ output/                           # All results here
    â”œâ”€â”€ ğŸ“ json_files/                   # Raw scraped data
    â”œâ”€â”€ ğŸ“ csv_files/                    # Processed CSV files
    â””â”€â”€ ğŸ“ excel_files/                  # Excel reports
```

## ğŸ¯ Workflow

1. **ğŸš€ Scrape:** `python run_scraper.py` â†’ Select options â†’ Scrape data
2. **ğŸ”§ Process:** `python optimized_multi_type_cleaner.py` â†’ Convert to CSV/Excel
3. **ğŸ“Š Analyze:** Open Excel files or use CSV files for analysis

## ğŸ”„ Proxy Support

The scraper supports multiple proxy options:
- **ScraperAPI** (Recommended) - Premium API service
- **Custom proxy files** - Load from text files
- **No proxies** - Direct connection

## ğŸ“ˆ Progress Tracking

- **Auto-save:** Data saved during scraping to prevent loss
- **Resume capability:** Continue from where you left off
- **Progress monitoring:** Check status with `python check_progress.py`

## ğŸ›¡ï¸ Features

- **Concurrent scraping:** 5 pages at once for speed
- **Retry logic:** Handles failures gracefully
- **Interrupt handling:** Safe data saving on Ctrl+C
- **Comprehensive data:** 37,000+ properties per major city
- **Clean output:** Optimized fields for each property type

---

**Happy Scraping!** ğŸ âœ¨